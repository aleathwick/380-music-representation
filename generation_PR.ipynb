{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import json\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see that the gpu is available\n",
    "print(tf..device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modules.mlClasses' from '/home/ubuntu/storage/380-music-representation/modules/mlClasses.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modules.midiMethods as midiMethods\n",
    "reload(midiMethods)\n",
    "from modules.midiMethods import *\n",
    "\n",
    "import modules.dataMethods as dataMethods\n",
    "reload(dataMethods)\n",
    "from modules.dataMethods import *\n",
    "\n",
    "import modules.models as models\n",
    "reload(models)\n",
    "\n",
    "import modules.mlClasses as mlClasses\n",
    "reload(mlClasses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Representation Sequence Generation\n",
    "This purpose of this notebook is to generate sequences using the Performance Representation/oore representation.\n",
    "Weights are loaded into a new model with the same architecture as at training time, but with sequence length of 1, and hidden states retained across batches. The choice of temperature is vitally important on the quality of the new sequences. Low temperatures emphasize more likely events; higher temperatures 'even out' the softmax distribution.\n",
    "See here for a very good tutorial on text generation: https://www.tensorflow.org/tutorials/text/text_generation\n",
    "\n",
    "### Model Without Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3layerLSTM\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(1, 600, 1)]             0         \n",
      "_________________________________________________________________\n",
      "lambda_11 (Lambda)           (1, 600, 242)             0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (1, 600, 512)             1546240   \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (1, 600, 512)             2099200   \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (1, 600, 512)             2099200   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (1, 600, 242)             124146    \n",
      "=================================================================\n",
      "Total params: 5,868,786\n",
      "Trainable params: 5,868,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tf.train.latest_checkpoint('weights\\first_attempt')\n",
    "hidden_state = 512\n",
    "lstm_layers = 3\n",
    "# n_events should be 242 or 333, depending on which version of oore was used\n",
    "prediction_model = models.create_ooremodel(batch_size=1, stateful=True, hidden_state_size=hidden_state, lstm_layers=lstm_layers, n_events=242, chroma=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some weights\n",
    "# if, at this point, there is an error in which two shapes differ by 12, that means the model should be rebuilt with/without chroma\n",
    "prediction_model.load_weights('models/oore/oore8/32-1.92.hdf5')\n",
    "# prediction_model.load_weights('weights/note_bin/model2_60epochs512state3layer.h5')\n",
    "# choose an input sequence to start things off with\n",
    "start = 'spa4'\n",
    "input_events = pm2oore2(pretty_midi.PrettyMIDI('midi/starts/spa2.mid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temperature in np.linspace(0,1,11):\n",
    "    new_seq_length = 600\n",
    "    new_seq = models.generate_ooremusic(prediction_model, new_seq_length, temperature=temperature, input_events=input_events)\n",
    "    new_seq_list = [int(event) for event in new_seq]\n",
    "    # convert to prettymidi object and write to file\n",
    "    pm = oore2pm2(new_seq_list)\n",
    "    pm.write(f'midi/oore/{start}-{new_seq_length}long-{temperature}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model With Chroma\n",
    "Code for generating sequences with chroma using PF does exist in models.py, but is currently untested."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
