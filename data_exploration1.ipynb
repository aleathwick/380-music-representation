{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache using fc-list. This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import json\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 422091078071127324\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13336856610618758248\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5588779008\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11742072890166847630\n",
      "physical_device_desc: \"device: 0, name: Tesla K20Xm, pci bus id: 0000:00:06.0, compute capability: 3.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 152799329061713978\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    reload(midiMethods)\n",
    "    from modules.midiMethods import *\n",
    "except:\n",
    "    print('reload failed')\n",
    "    import modules.midiMethods as midiMethods\n",
    "    from modules.midiMethods import *\n",
    "try:\n",
    "    reload(dataMethods)\n",
    "    from modules.dataMethods import *\n",
    "except:\n",
    "    print('reload failed')\n",
    "    import modules.dataMethods as dataMethods\n",
    "    from modules.dataMethods import *\n",
    "import modules.mlClasses as mlClasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modules.mlClasses' from '/home/ubuntu/music-ml/380-music-representation/modules/mlClasses.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import modules.models as models\n",
    "reload(models)\n",
    "import modules.mlClasses as mlClasses\n",
    "reload(mlClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, read in filenames...\n",
    "maestro = pd.read_csv('training_data/maestro-v2.0.0withPeriod.csv', index_col=0)\n",
    "filenames = list(maestro['midi_filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or process data set\n",
    "data_path = 'C:/Users\\Andrew/Documents/mlprojects/Datasets/MaestroV2.00/maestro-v2.0.0/'\n",
    "examples = files2note_bin_examples(data_path, skip=1, speed=0.9)\n",
    "print(len(examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store examples in json format\n",
    "with open('training_data/training_data_note_bin_complete.json', 'w') as f:\n",
    "    json.dump(examples, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or read them in\n",
    "with open('training_data/training_data_note_bin_complete.json', 'r') as f:\n",
    "    examples = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"2layerLSTM\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 128, 88)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128, 10)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128, 60)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 128, 18)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 128, 30)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 128, 32)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 238)     0           lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128, 256)     506880      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128, 256)     525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 88)      22616       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 10)      2570        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128, 60)      15420       lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128, 18)      4626        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128, 30)      7710        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128, 32)      8224        lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,093,358\n",
      "Trainable params: 1,093,358\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build simple model\n",
    "# excellent example of recurrent model here https://www.tensorflow.org/tutorials/text/text_generation\n",
    "hidden_state = 256\n",
    "lstm_layers = 2\n",
    "model2 = models.create_model1(hidden_state_size=hidden_state, lstm_layers=lstm_layers)\n",
    "training_generator = mlClasses.DataGenerator(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 48/803 [>.............................] - ETA: 2:48 - loss: 9.9842 - dense_loss: 2.6868 - dense_1_loss: 0.0442 - dense_2_loss: 2.2681 - dense_3_loss: 0.3712 - dense_4_loss: 2.2444 - dense_5_loss: 2.3696 - dense_accuracy: 0.2767 - dense_1_accuracy: 0.9873 - dense_2_accuracy: 0.2811 - dense_3_accuracy: 0.8807 - dense_4_accuracy: 0.3067 - dense_5_accuracy: 0.1825"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3f1ef1746ff8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights/model1/{epoch:02d}-{train_loss:.2f}.hdf5\", monitor='train_loss', verbose=2, save_best_only=True, save_weights_only=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/note_bin/model2_10epochs256state2layer.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m   metrics_results = _eager_metrics_fn(\n\u001b[0;32m--> 315\u001b[0;31m       model, outs, targets, sample_weights=sample_weights, masks=masks)\n\u001b[0m\u001b[1;32m    316\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m   return {'total_loss': total_loss,\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_eager_metrics_fn\u001b[0;34m(model, outputs, targets, sample_weights, masks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mmasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mreturn_weighted_and_unweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         skip_target_masks=model._prepare_skip_target_masks())\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m   \u001b[0;31m# Add metric results from the `add_metric` metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_metrics\u001b[0;34m(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics)\u001b[0m\n\u001b[1;32m   2061\u001b[0m           metric_results.extend(\n\u001b[1;32m   2062\u001b[0m               self._handle_per_output_metrics(self._per_output_metrics[i],\n\u001b[0;32m-> 2063\u001b[0;31m                                               target, output, output_mask))\n\u001b[0m\u001b[1;32m   2064\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_weighted_and_unweighted_metrics\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreturn_weighted_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m           metric_results.extend(\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_handle_per_output_metrics\u001b[0;34m(self, metrics_dict, y_true, y_pred, mask, weights)\u001b[0m\n\u001b[1;32m   2012\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         metric_result = training_utils.call_metric_function(\n\u001b[0;32m-> 2014\u001b[0;31m             metric_fn, y_true, y_pred, weights=weights, mask=mask)\n\u001b[0m\u001b[1;32m   2015\u001b[0m         \u001b[0mmetric_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcall_metric_function\u001b[0;34m(metric_fn, y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m   \u001b[0;31m# `Mean` metric only takes a single value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m  \u001b[0;31m# pylint:disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     return distributed_training_utils.call_replica_local_fn(\n\u001b[0;32m--> 193\u001b[0;31m         replica_local_fn, *args, **kwargs)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py\u001b[0m in \u001b[0;36mcall_replica_local_fn\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36mreplica_local_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreplica_local_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;34m\"\"\"Updates the state of the metric in a replica-local context.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[0;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[1;32m    571\u001b[0m       \u001b[0mUpdate\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    702\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Casting complex to real discards imaginary part.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/music/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, DstT, Truncate, name)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cast\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DstT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDstT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Truncate\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m         Truncate)\n\u001b[0m\u001b[1;32m   2200\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights/model1/{epoch:02d}-{train_loss:.2f}.hdf5\", monitor='train_loss', verbose=2, save_best_only=True, save_weights_only=True)\n",
    "history = model2.fit_generator(training_generator, epochs=10)\n",
    "model2.save_weights('weights/note_bin/model2_10epochs256state2layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'modules.models' from '/home/ubuntu/music-ml/380-music-representation/modules/models.py'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This works just like this:\n",
    "import modules.models as models\n",
    "reload(models)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"2layerLSTM\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(1, 128, 6)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (1, 128, 88)         0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (1, 128, 10)         0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (1, 128, 60)         0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (1, 128, 18)         0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (1, 128, 30)         0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (1, 128, 32)         0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (1, 128, 238)        0           lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (1, 128, 256)        506880      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (1, 128, 256)        525312      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (1, 128, 88)         22616       lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (1, 128, 10)         2570        lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (1, 128, 60)         15420       lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (1, 128, 18)         4626        lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (1, 128, 30)         7710        lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (1, 128, 32)         8224        lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,093,358\n",
      "Trainable params: 1,093,358\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tf.train.latest_checkpoint('weights\\first_attempt')\n",
    "prediction_model = models.create_model1(batch_size=1, stateful=True, hidden_state_size=hidden_state, lstm_layers=lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44, 0, 0, 4, 3, 20]\n",
      "[48, 0, 0, 4, 3, 20]\n",
      "[51, 0, 0, 3, 3, 20]\n",
      "[[44, 0, 0, 4, 3, 20], [48, 0, 0, 4, 3, 20], [51, 0, 0, 3, 3, 20], [58, 0, 41, 3, 20, 23], [49, 0, 56, 3, 0, 25], [60, 0, 47, 3, 26, 11], [69, 0, 26, 3, 25, 4], [87, 0, 46, 3, 18, 30], [19, 0, 3, 3, 1, 21], [44, 0, 23, 2, 28, 23], [64, 0, 44, 2, 25, 21], [55, 0, 9, 2, 25, 20], [23, 0, 32, 2, 13, 18], [36, 0, 51, 2, 2, 5], [9, 0, 7, 1, 1, 7], [26, 0, 37, 1, 7, 6], [24, 0, 49, 1, 28, 9], [33, 0, 53, 3, 29, 11], [82, 0, 27, 1, 3, 19], [81, 0, 31, 1, 2, 11], [48, 0, 23, 0, 14, 21], [16, 0, 6, 0, 28, 11], [17, 0, 11, 0, 13, 21], [85, 0, 49, 2, 16, 16], [45, 0, 8, 2, 14, 9], [45, 0, 1, 2, 4, 8], [53, 0, 35, 2, 23, 14], [16, 0, 13, 2, 2, 23], [37, 0, 35, 1, 20, 13], [29, 0, 22, 1, 14, 29], [51, 0, 52, 0, 25, 27], [76, 0, 36, 0, 11, 9], [13, 0, 8, 3, 20, 6], [38, 0, 45, 3, 13, 26], [32, 0, 30, 3, 14, 19], [80, 0, 26, 2, 28, 31], [41, 0, 19, 2, 28, 2], [81, 0, 24, 2, 4, 28], [36, 0, 37, 1, 18, 28], [5, 0, 24, 1, 18, 2], [25, 0, 10, 1, 5, 18], [17, 0, 37, 8, 8, 15], [36, 0, 31, 7, 9, 28], [46, 0, 50, 6, 22, 15], [62, 0, 45, 6, 24, 24], [26, 0, 0, 6, 22, 30], [64, 0, 48, 6, 0, 10], [85, 0, 58, 5, 26, 26], [66, 0, 31, 5, 21, 2], [77, 0, 5, 4, 2, 3], [70, 0, 4, 4, 8, 6], [74, 0, 58, 4, 10, 1], [68, 0, 9, 4, 8, 0], [50, 0, 6, 4, 26, 14], [76, 0, 53, 4, 3, 4], [71, 0, 16, 3, 0, 16], [29, 0, 21, 2, 26, 12], [19, 0, 12, 2, 6, 30], [85, 0, 10, 1, 24, 28], [63, 0, 38, 1, 19, 15], [39, 0, 9, 1, 22, 25], [31, 0, 20, 1, 11, 8], [35, 0, 41, 1, 14, 29], [60, 0, 1, 0, 0, 13], [36, 0, 18, 0, 2, 27], [21, 0, 44, 0, 0, 25], [22, 0, 0, 0, 0, 22], [14, 0, 38, 0, 21, 9], [80, 0, 16, 0, 21, 12], [38, 0, 10, 0, 8, 0], [32, 0, 2, 0, 25, 21], [53, 0, 44, 0, 20, 13], [21, 0, 11, 0, 15, 12], [51, 0, 17, 0, 14, 31], [5, 0, 15, 0, 14, 16], [4, 0, 53, 0, 18, 19], [52, 0, 52, 0, 21, 10], [21, 0, 2, 0, 12, 8], [30, 0, 7, 0, 5, 7], [62, 0, 13, 0, 3, 9], [23, 0, 51, 0, 2, 1], [36, 0, 2, 0, 2, 0], [32, 0, 1, 0, 2, 17], [3, 0, 41, 0, 2, 17], [87, 0, 7, 0, 2, 31], [43, 0, 17, 0, 2, 23], [4, 0, 25, 0, 21, 14], [72, 0, 0, 0, 20, 3], [11, 0, 3, 0, 19, 26], [7, 0, 1, 0, 6, 16], [30, 0, 54, 0, 3, 4], [15, 0, 7, 0, 3, 6], [84, 0, 38, 0, 3, 10], [12, 0, 31, 0, 10, 25], [54, 0, 41, 0, 10, 17], [52, 0, 15, 0, 6, 16], [35, 0, 38, 0, 3, 4], [42, 0, 44, 0, 2, 8], [13, 0, 12, 0, 2, 23], [37, 0, 57, 0, 2, 27], [74, 0, 52, 0, 2, 0], [50, 0, 2, 0, 2, 3], [74, 0, 1, 0, 2, 29], [63, 0, 31, 0, 2, 2], [54, 0, 23, 0, 2, 7], [75, 0, 3, 0, 2, 4], [6, 0, 50, 0, 2, 31], [62, 0, 48, 0, 1, 19], [87, 0, 28, 0, 24, 19], [45, 0, 31, 0, 9, 3], [76, 0, 4, 0, 9, 24], [72, 0, 0, 0, 10, 31], [78, 0, 11, 0, 21, 14], [40, 0, 43, 0, 7, 17], [79, 0, 26, 0, 8, 17], [85, 0, 0, 0, 0, 24], [63, 0, 47, 0, 20, 27], [30, 0, 0, 0, 20, 30], [12, 0, 0, 0, 20, 30], [43, 0, 36, 0, 20, 22], [51, 0, 0, 0, 19, 21], [69, 0, 41, 0, 19, 20], [41, 0, 1, 0, 18, 13], [45, 0, 57, 0, 20, 9], [74, 0, 1, 0, 19, 9], [1, 0, 21, 0, 19, 20], [76, 0, 57, 0, 7, 19], [28, 0, 56, 0, 24, 9], [50, 0, 2, 0, 16, 13], [13, 0, 52, 0, 23, 1], [9, 0, 0, 0, 10, 2]]\n"
     ]
    }
   ],
   "source": [
    "prediction_model.load_weights('weights/note_bin/model2_10epochs256state2layer.h5')\n",
    "# temperatures = [0.1] * 6\n",
    "temperatures = [5, 0.12, 0.12, 0.1, 0.1, 5]\n",
    "input_notes = [[44,0,0,4,3,20], [48,0,0,4,3,20], [51,0,0,3,3,20],[56,0,5,3,3,20]]\n",
    "new_seq = models.generate_music(prediction_model, temperatures, input_notes)\n",
    "ns = [[int(a) for a in note] for note in new_seq]\n",
    "print(ns)\n",
    "pm = note_bin2pm(ns)\n",
    "pm.write(f'midi/model2/{temperatures}b.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "models.plt_metric(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33, 0, 0, 7, 13, 12],\n",
       " [40, 0, 4, 7, 11, 12],\n",
       " [37, 0, 1, 7, 10, 12],\n",
       " [21, 0, 53, 5, 4, 13],\n",
       " [31, 0, 52, 5, 18, 12],\n",
       " [19, 0, 4, 5, 16, 5],\n",
       " [31, 0, 40, 4, 26, 13],\n",
       " [19, 0, 2, 4, 25, 12],\n",
       " [45, 1, 40, 3, 0, 17],\n",
       " [33, 0, 1, 3, 5, 13],\n",
       " [19, 0, 50, 2, 10, 12],\n",
       " [31, 0, 0, 2, 10, 12],\n",
       " [45, 0, 30, 1, 20, 18],\n",
       " [38, 0, 2, 1, 18, 13],\n",
       " [33, 0, 2, 1, 23, 13],\n",
       " [35, 0, 0, 1, 23, 10],\n",
       " [33, 0, 26, 1, 10, 12],\n",
       " [21, 0, 0, 4, 5, 17],\n",
       " [29, 0, 28, 0, 17, 18],\n",
       " [17, 0, 0, 0, 17, 16],\n",
       " [29, 0, 35, 3, 4, 15],\n",
       " [17, 0, 0, 2, 18, 15],\n",
       " [50, 0, 4, 3, 2, 21],\n",
       " [38, 0, 1, 3, 1, 16],\n",
       " [47, 0, 0, 3, 1, 17],\n",
       " [45, 0, 1, 2, 27, 14],\n",
       " [38, 1, 26, 1, 18, 15],\n",
       " [35, 0, 1, 1, 17, 17],\n",
       " [45, 0, 23, 1, 2, 20],\n",
       " [33, 0, 2, 1, 3, 16],\n",
       " [17, 0, 38, 0, 18, 12],\n",
       " [29, 0, 1, 0, 15, 14],\n",
       " [45, 0, 11, 0, 6, 15],\n",
       " [33, 0, 0, 0, 7, 16],\n",
       " [43, 0, 6, 0, 5, 2],\n",
       " [45, 0, 6, 5, 28, 20],\n",
       " [33, 0, 2, 5, 25, 19],\n",
       " [37, 0, 0, 5, 27, 15],\n",
       " [43, 0, 2, 5, 26, 1],\n",
       " [33, 0, 26, 5, 10, 14],\n",
       " [21, 0, 1, 5, 6, 15],\n",
       " [16, 0, 37, 4, 23, 16],\n",
       " [28, 0, 1, 4, 23, 16],\n",
       " [28, 0, 52, 3, 27, 16],\n",
       " [16, 0, 1, 3, 26, 15],\n",
       " [44, 1, 29, 2, 12, 19],\n",
       " [32, 0, 1, 2, 11, 15],\n",
       " [16, 1, 31, 0, 25, 15],\n",
       " [28, 0, 0, 0, 25, 13],\n",
       " [45, 0, 7, 0, 21, 21],\n",
       " [33, 0, 1, 0, 19, 18],\n",
       " [21, 0, 32, 4, 20, 18],\n",
       " [46, 0, 5, 4, 17, 23],\n",
       " [34, 0, 2, 4, 16, 19],\n",
       " [33, 0, 0, 4, 16, 7],\n",
       " [38, 0, 1, 4, 16, 18],\n",
       " [41, 0, 2, 4, 15, 15],\n",
       " [45, 0, 0, 4, 15, 15],\n",
       " [29, 0, 36, 3, 27, 10],\n",
       " [17, 0, 0, 3, 27, 17],\n",
       " [14, 0, 19, 3, 17, 20],\n",
       " [14, 0, 7, 3, 13, 19],\n",
       " [57, 0, 24, 3, 1, 23],\n",
       " [45, 0, 1, 3, 1, 19],\n",
       " [50, 0, 1, 3, 0, 19],\n",
       " [53, 0, 0, 3, 0, 19],\n",
       " [34, 0, 2, 3, 0, 17],\n",
       " [41, 0, 0, 2, 29, 15],\n",
       " [46, 0, 2, 2, 28, 16],\n",
       " [33, 1, 19, 1, 19, 19],\n",
       " [33, 0, 12, 1, 13, 18],\n",
       " [56, 0, 2, 1, 12, 24],\n",
       " [44, 0, 0, 1, 12, 20],\n",
       " [53, 0, 0, 1, 11, 19],\n",
       " [50, 0, 1, 1, 11, 18],\n",
       " [38, 0, 5, 1, 8, 13],\n",
       " [41, 0, 2, 1, 7, 17],\n",
       " [53, 0, 23, 0, 26, 22],\n",
       " [41, 0, 1, 0, 26, 18],\n",
       " [50, 0, 14, 0, 19, 23],\n",
       " [38, 0, 1, 0, 18, 21],\n",
       " [21, 0, 12, 0, 12, 18],\n",
       " [45, 0, 3, 0, 11, 22],\n",
       " [33, 0, 1, 0, 11, 22],\n",
       " [34, 0, 11, 0, 5, 21],\n",
       " [46, 0, 0, 0, 5, 22],\n",
       " [42, 0, 4, 0, 3, 12],\n",
       " [47, 0, 7, 3, 23, 22],\n",
       " [21, 0, 0, 3, 20, 17],\n",
       " [42, 0, 0, 3, 23, 17],\n",
       " [33, 0, 2, 3, 21, 14],\n",
       " [38, 0, 0, 3, 22, 17],\n",
       " [39, 0, 0, 3, 22, 16],\n",
       " [37, 0, 1, 3, 21, 13],\n",
       " [48, 0, 3, 3, 18, 10],\n",
       " [45, 0, 1, 3, 19, 13],\n",
       " [36, 0, 1, 3, 18, 10],\n",
       " [37, 0, 0, 3, 19, 6],\n",
       " [29, 0, 12, 3, 13, 19],\n",
       " [17, 0, 0, 3, 13, 18],\n",
       " [26, 0, 14, 3, 6, 20],\n",
       " [14, 0, 0, 3, 6, 18],\n",
       " [26, 0, 9, 3, 1, 20],\n",
       " [14, 0, 2, 3, 0, 10],\n",
       " [57, 0, 19, 2, 21, 24],\n",
       " [50, 0, 2, 2, 19, 21],\n",
       " [35, 0, 1, 2, 19, 18],\n",
       " [53, 0, 1, 2, 19, 20],\n",
       " [41, 0, 0, 2, 19, 14],\n",
       " [47, 0, 1, 2, 18, 18],\n",
       " [37, 0, 5, 2, 16, 7],\n",
       " [48, 0, 51, 1, 19, 19],\n",
       " [36, 0, 0, 1, 19, 20],\n",
       " [21, 0, 22, 1, 6, 19],\n",
       " [33, 0, 1, 1, 7, 15],\n",
       " [21, 0, 10, 1, 1, 20],\n",
       " [45, 0, 2, 1, 3, 19],\n",
       " [38, 0, 0, 1, 3, 18],\n",
       " [33, 0, 2, 1, 1, 8],\n",
       " [41, 0, 0, 1, 2, 14],\n",
       " [15, 0, 18, 0, 23, 11],\n",
       " [17, 0, 1, 0, 22, 9],\n",
       " [48, 0, 3, 0, 19, 23],\n",
       " [36, 0, 1, 0, 19, 20],\n",
       " [14, 0, 12, 0, 14, 16],\n",
       " [21, 0, 22, 2, 17, 15],\n",
       " [48, 0, 3, 2, 21, 23],\n",
       " [33, 0, 1, 2, 15, 12],\n",
       " [40, 0, 0, 2, 20, 14]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[330]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
